{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arun-nexus/deep_learning/blob/main/english_to_french.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350c30b4",
      "metadata": {
        "id": "350c30b4",
        "outputId": "8e5d2662-3758-4fca-93ae-92592d00eeca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Qui ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English words/sentences French words/sentences\n",
              "0                     Hi.                 Salut!\n",
              "1                    Run!                Cours !\n",
              "2                    Run!               Courez !\n",
              "3                    Who?                  Qui ?\n",
              "4                    Wow!             Ça alors !"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(r\"C:\\Users\\Arun\\Downloads\\eng_-french.csv\\eng_-french.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3554a859",
      "metadata": {
        "id": "3554a859",
        "outputId": "47c297df-d62e-4818-ab29-475deb2a9dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English words/sentences    0\n",
            "French words/sentences     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc72bce",
      "metadata": {
        "id": "5bc72bce"
      },
      "outputs": [],
      "source": [
        "english=df[\"English words/sentences\"].to_list()\n",
        "french=df[\"French words/sentences\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6efe58fb",
      "metadata": {
        "id": "6efe58fb"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "def tokenize(text):\n",
        "    tokens=[word_tokenize(word) for word in text]\n",
        "    return tokens\n",
        "english_tokens=tokenize(english)\n",
        "french_tokens=tokenize(french)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce2ea3f",
      "metadata": {
        "id": "2ce2ea3f"
      },
      "outputs": [],
      "source": [
        "english_seq=[]\n",
        "french_seq=[]\n",
        "def sequence(tokens,list):\n",
        "    [list.append(word) for row in tokens for word in row]\n",
        "    return list\n",
        "english_seq=sequence(english_tokens,english_seq)\n",
        "french_seq=sequence(french_tokens,french_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "341e6e3c",
      "metadata": {
        "id": "341e6e3c"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "english_word_count=Counter(english_seq)\n",
        "french_word_count=Counter(french_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ea0f36",
      "metadata": {
        "id": "36ea0f36"
      },
      "outputs": [],
      "source": [
        "english_dict={\"<pad>\":0,\"<unk>\":1}\n",
        "french_dict={\"<pad>\":0,\"<unk>\":1}\n",
        "def dict(counter,dict):\n",
        "    for key in counter:\n",
        "        if key not in dict:\n",
        "            dict[key]=len(dict)\n",
        "    return dict\n",
        "english_dict=dict(english_word_count,english_dict)\n",
        "french_dict=dict(french_word_count,french_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c4002f",
      "metadata": {
        "id": "c1c4002f"
      },
      "outputs": [],
      "source": [
        "src_vocab=len(english_dict)\n",
        "tgt_vocab=len(french_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09bf2e02",
      "metadata": {
        "id": "09bf2e02"
      },
      "outputs": [],
      "source": [
        "def data(tokens,dict):\n",
        "    sequence=[]\n",
        "    for row in tokens:\n",
        "        dataset=[dict.get(word,dict[\"<unk>\"]) for word in row]\n",
        "        sequence.append(dataset)\n",
        "    return sequence\n",
        "english_dataset=data(english_tokens,english_dict)\n",
        "french_dataset=data(french_tokens,french_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3edb5946",
      "metadata": {
        "id": "3edb5946"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "def padded_tensor(dataset):\n",
        "    dataset=[torch.tensor(row,dtype=torch.long) for row in dataset]\n",
        "    padded_data=pad_sequence(dataset)\n",
        "    return padded_data\n",
        "english_padded_data=padded_tensor(english_dataset)\n",
        "french_padded_data=padded_tensor(french_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d1c6a4",
      "metadata": {
        "id": "47d1c6a4"
      },
      "outputs": [],
      "source": [
        "english_padded_data=english_padded_data.T\n",
        "french_padded_data=french_padded_data.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e50268",
      "metadata": {
        "id": "a6e50268",
        "outputId": "ed091f72-3e51-4409-ea31-dcc84cbaef76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([175621, 59])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "french_padded_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80821cb0",
      "metadata": {
        "id": "80821cb0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset=TensorDataset(english_padded_data,french_padded_data)\n",
        "train_data,val_data=train_test_split(dataset,test_size=0.3,random_state=21)\n",
        "train_data_loader=DataLoader(train_data,batch_size=210)\n",
        "val_data_loader=DataLoader(val_data,batch_size=210)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18fd8d3",
      "metadata": {
        "id": "a18fd8d3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "class positional_encoding(nn.Module):\n",
        "    def __init__(self,max_len=int(59),d_model=int(21)):\n",
        "        super().__init__()\n",
        "        pe=torch.zeros(max_len,d_model)\n",
        "        position=torch.arange(0,max_len).unsqueeze(1)\n",
        "        div_term=torch.exp(torch.arange(0,d_model,2)*(-math.log(10000.0)/d_model))\n",
        "        pe[:,0::2]=torch.sin(position*div_term)\n",
        "        pe[:,1::2]=torch.cos(position*div_term)\n",
        "        pe=pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\",pe)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x+self.pe[:,:x.size(1)]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f4a605",
      "metadata": {
        "id": "b3f4a605"
      },
      "outputs": [],
      "source": [
        "class attention(nn.Module):\n",
        "    def __init__(self,d_model,num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.num_heads=num_heads\n",
        "\n",
        "        self.q_linear=nn.Linear(d_model,d_model)\n",
        "        self.k_linear=nn.Linear(d_model,d_model)\n",
        "        self.v_linear=nn.Linear(d_model,d_model)\n",
        "        self.out=nn.Linear(d_model,d_model)\n",
        "\n",
        "    def forward(self,q,k,v,mask=None):\n",
        "        batch_size=q.size(0)\n",
        "        q=self.q_linear(q).view(batch_size,-1,self.num_heads,self.d_k).transpose(1,2)\n",
        "        k=self.k_linear(k).view(batch_size,-1,self.num_heads,self.d_k).transpose(1,2)\n",
        "        v=self.v_linear(v).view(batch_size,-1,self.num_heads,self.d_k).transpose(1,2)\n",
        "        scores=torch.matmul(q,k.transpose(-2,-1))/math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores=scores.masked_fill(mask==0,float(\"inf\"))\n",
        "        attn=torch.softmax(scores,dim=-1)\n",
        "        output=torch.matmul(attn,v)\n",
        "        output=output.transpose(1,2).contiguous().view(batch_size,-1,self.num_heads*self.d_k)\n",
        "        return self.out(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4545fd57",
      "metadata": {
        "id": "4545fd57"
      },
      "outputs": [],
      "source": [
        "class forward(nn.Module):\n",
        "    def __init__(self,d_model,d_ff=2048,drop=0.1):\n",
        "        super().__init__()\n",
        "        self.features=nn.Sequential(\n",
        "            nn.Linear(d_model,d_ff),nn.ReLU(),nn.Dropout(drop),nn.Linear(d_ff,d_model)\n",
        "            )\n",
        "    def forward(self,x):\n",
        "        return self.features(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2163ae14",
      "metadata": {
        "id": "2163ae14"
      },
      "outputs": [],
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self,d_model,num_heads,d_ff,drop=0.1):\n",
        "        super().__init__()\n",
        "        self.attn=attention(d_model,num_heads)\n",
        "        self.norm=nn.LayerNorm(d_model)\n",
        "        self.norm2=nn.LayerNorm(d_model)\n",
        "        self.ff=forward(d_model,d_ff,drop)\n",
        "        self.drop=nn.Dropout(drop)\n",
        "\n",
        "    def forward(self,x,mask=None):\n",
        "        attn=self.attn(x,x,x,mask)\n",
        "        x=self.norm(x+self.drop(attn))\n",
        "        ff=self.ff(x)\n",
        "        x=self.norm2(x+self.drop(ff))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf5f91c",
      "metadata": {
        "id": "acf5f91c"
      },
      "outputs": [],
      "source": [
        "class decoder(nn.Module):\n",
        "    def __init__(self,d_model,num_heads,d_ff,drop):\n",
        "        super().__init__()\n",
        "        self.masked_attn=attention(d_model,num_heads)\n",
        "        self.cross_attn=attention(d_model,num_heads)\n",
        "        self.norm1=nn.LayerNorm(d_model)\n",
        "        self.norm2=nn.LayerNorm(d_model)\n",
        "        self.norm3=nn.LayerNorm(d_model)\n",
        "        self.ff=forward(d_model,d_ff,drop)\n",
        "        self.drop=nn.Dropout(drop)\n",
        "    def forward(self,x,enc_out,src_mask=None,mask=None):\n",
        "        mask_attn=self.masked_attn(x,x,x,mask)\n",
        "        x=self.norm1(x+self.drop(mask_attn))\n",
        "        cross_atten=self.cross_attn(x,enc_out,enc_out,src_mask)\n",
        "        x=self.norm2(x+self.drop(cross_atten))\n",
        "        ff=self.ff(x)\n",
        "        x=self.norm3(x+self.drop(ff))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88098ac",
      "metadata": {
        "id": "c88098ac"
      },
      "outputs": [],
      "source": [
        "class transformer(nn.Module):\n",
        "    def __init__(self,src_vocab,tgt_vocab,d_model,max_len,num_heads,d_ff,num_layers,drop=0.1):\n",
        "        super().__init__()\n",
        "        self.src_embedding=nn.Embedding(src_vocab,d_model)\n",
        "        self.tgt_embedding=nn.Embedding(tgt_vocab,d_model)\n",
        "        self.pos_enc=positional_encoding(max_len,d_model)\n",
        "\n",
        "        self.encoder=nn.ModuleList([encoder(d_model,num_heads,d_ff,drop) for _ in range(num_layers)])\n",
        "        self.decoder=nn.ModuleList([decoder(d_model,num_heads,d_ff,drop) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc_out=nn.Linear(d_model,tgt_vocab)\n",
        "\n",
        "    def forward(self,src,tgt,src_mask=None,tgt_mask=None):\n",
        "        src=self.pos_enc(self.src_embedding(src))\n",
        "        tgt=self.pos_enc(self.tgt_embedding(tgt))\n",
        "\n",
        "        for layers in self.encoder:\n",
        "            src=layers(src,src_mask)\n",
        "        for layers in self.decoder:\n",
        "            tgt=layers(tgt,src,src_mask,tgt_mask)\n",
        "        return self.fc_out(tgt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4e936f",
      "metadata": {
        "id": "fb4e936f"
      },
      "outputs": [],
      "source": [
        "device=(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=transformer(src_vocab=src_vocab,tgt_vocab=tgt_vocab,d_model=512,max_len=59,num_heads=8,d_ff=1024,drop=0.2,num_layers=6).to(device)\n",
        "model_loss=nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "scheduler=ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65da6a4d",
      "metadata": {
        "id": "65da6a4d"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class early_stopping(nn.Module):\n",
        "    def __init__(self,min_delta,patience):\n",
        "        super().__init__()\n",
        "        self.min_delta=min_delta\n",
        "        self.partience=patience\n",
        "        self.early_stop=False\n",
        "        self.best_loss=float(\"inf\")\n",
        "        self.counter=0\n",
        "\n",
        "    def __call__(self,val_loss):\n",
        "        if self.min_delta >= val_loss-self.best_loss:\n",
        "            self.counter=0\n",
        "            self.best_loss=val_loss\n",
        "        else:\n",
        "            self.counter+=1\n",
        "            if self.counter>=self.partience:\n",
        "                self.early_stop=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2495c60a",
      "metadata": {
        "id": "2495c60a"
      },
      "outputs": [],
      "source": [
        "from torch.amp import GradScaler,autocast\n",
        "epochs=50\n",
        "stopper=early_stopping(1e-4,4)\n",
        "training_loss_store=[]\n",
        "validation_loss_store=[]\n",
        "training_accuracy_store=[]\n",
        "validation_accuracy_store=[]\n",
        "scaler=GradScaler()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running,total,correct=0,0,0\n",
        "    for x,y in train_data_loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(\"cuda\"):\n",
        "            output=model(x,y)\n",
        "            output=output.view(-1,output.shape[-1])\n",
        "            y=y.view(-1)\n",
        "            # print(output.shape,y.shape)\n",
        "            loss=model_loss(output,y)\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running+=loss.item()*y.size(0)\n",
        "        _,pred=torch.max(output,1)\n",
        "        mask=y!=0\n",
        "        correct+=((pred==y)&mask).sum().item()\n",
        "        total+=mask.sum().item()\n",
        "        # print(torch.isnan(pred).any(), torch.isnan(y).any())\n",
        "\n",
        "    training_loss=running/total\n",
        "    training_acc=correct/total\n",
        "    training_loss_store.append(training_loss)\n",
        "    training_accuracy_store.append(training_acc)\n",
        "\n",
        "    model.eval()\n",
        "    vrunning,vtotal,vcorrect=0,0,0\n",
        "    for x,y in val_data_loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(\"cuda\"):\n",
        "            voutput=model(x,y)\n",
        "            voutput=voutput.view(-1,voutput.shape[-1])\n",
        "            y=y.view(-1)\n",
        "            vloss=model_loss(voutput,y)\n",
        "\n",
        "        vrunning+=vloss.item()*y.size(0)\n",
        "        _,vpred=torch.max(voutput,1)\n",
        "        mask=y!=0\n",
        "        vcorrect+=((vpred==y)&mask).sum().item()\n",
        "        vtotal+=mask.sum().item()\n",
        "    val_loss=vrunning/vtotal\n",
        "    val_acc=vcorrect/vtotal\n",
        "    validation_loss_store.append(val_loss)\n",
        "    validation_accuracy_store.append(val_acc)\n",
        "\n",
        "    print(f\"epoch: {epoch+1} training_loss: {training_loss:.4f} training acc:{training_acc:.2f} validation_loss: {val_loss:.4f} validation_acc: {val_acc:.2f} \")\n",
        "    stopper(val_loss)\n",
        "    if stopper.early_stop:\n",
        "        print(\"early_stopping triggered\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e522d70",
      "metadata": {
        "id": "1e522d70"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a68477",
      "metadata": {
        "id": "40a68477"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}