{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arun-nexus/deep_learning/blob/main/question_answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f0d7277",
      "metadata": {
        "id": "6f0d7277",
        "outputId": "23e8ead3-6e49-4b68-e68d-b61c19a866d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>distractor3</th>\n",
              "      <th>distractor1</th>\n",
              "      <th>distractor2</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What type of organism is commonly used in prep...</td>\n",
              "      <td>viruses</td>\n",
              "      <td>protozoa</td>\n",
              "      <td>gymnosperms</td>\n",
              "      <td>mesophilic organisms</td>\n",
              "      <td>Mesophiles grow best in moderate temperature, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What phenomenon makes global winds blow northe...</td>\n",
              "      <td>tropical effect</td>\n",
              "      <td>muon effect</td>\n",
              "      <td>centrifugal effect</td>\n",
              "      <td>coriolis effect</td>\n",
              "      <td>Without Coriolis Effect the global winds would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Changes from a less-ordered state to a more-or...</td>\n",
              "      <td>endothermic</td>\n",
              "      <td>unbalanced</td>\n",
              "      <td>reactive</td>\n",
              "      <td>exothermic</td>\n",
              "      <td>Summary Changes of state are examples of phase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the least dangerous radioactive decay?</td>\n",
              "      <td>zeta decay</td>\n",
              "      <td>beta decay</td>\n",
              "      <td>gamma decay</td>\n",
              "      <td>alpha decay</td>\n",
              "      <td>All radioactive decay is dangerous to living t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kilauea in hawaii is the world’s most continuo...</td>\n",
              "      <td>magma</td>\n",
              "      <td>greenhouse gases</td>\n",
              "      <td>carbon and smog</td>\n",
              "      <td>smoke and ash</td>\n",
              "      <td>Example 3.5 Calculating Projectile Motion: Hot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11674</th>\n",
              "      <td>The enzyme pepsin plays an important role in t...</td>\n",
              "      <td>lipids</td>\n",
              "      <td>protons</td>\n",
              "      <td>proteins</td>\n",
              "      <td>peptides</td>\n",
              "      <td>Protein A large part of protein digestion take...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11675</th>\n",
              "      <td>What remains a constant of radioactive substan...</td>\n",
              "      <td>acidity</td>\n",
              "      <td>temperature</td>\n",
              "      <td>volatility</td>\n",
              "      <td>rate of decay</td>\n",
              "      <td>The rate of decay of a radioactive substance i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11676</th>\n",
              "      <td>Terrestrial ecosystems, also known for their d...</td>\n",
              "      <td>substrates</td>\n",
              "      <td>bisomes</td>\n",
              "      <td>monomes</td>\n",
              "      <td>biomes</td>\n",
              "      <td>Terrestrial ecosystems, also known for their d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11677</th>\n",
              "      <td>High explosives create shock waves that exceed...</td>\n",
              "      <td>turbulence</td>\n",
              "      <td>light speed</td>\n",
              "      <td>ion speed</td>\n",
              "      <td>supersonic</td>\n",
              "      <td>The modern day formulation of gun powder is ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11678</th>\n",
              "      <td>What do you call a structure composed of two o...</td>\n",
              "      <td>system</td>\n",
              "      <td>cell</td>\n",
              "      <td>marrow</td>\n",
              "      <td>organ</td>\n",
              "      <td>An organ is a structure composed of two or mor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11679 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question      distractor3  \\\n",
              "0      What type of organism is commonly used in prep...          viruses   \n",
              "1      What phenomenon makes global winds blow northe...  tropical effect   \n",
              "2      Changes from a less-ordered state to a more-or...      endothermic   \n",
              "3         What is the least dangerous radioactive decay?       zeta decay   \n",
              "4      Kilauea in hawaii is the world’s most continuo...            magma   \n",
              "...                                                  ...              ...   \n",
              "11674  The enzyme pepsin plays an important role in t...           lipids   \n",
              "11675  What remains a constant of radioactive substan...          acidity   \n",
              "11676  Terrestrial ecosystems, also known for their d...       substrates   \n",
              "11677  High explosives create shock waves that exceed...       turbulence   \n",
              "11678  What do you call a structure composed of two o...           system   \n",
              "\n",
              "            distractor1         distractor2        correct_answer  \\\n",
              "0              protozoa         gymnosperms  mesophilic organisms   \n",
              "1           muon effect  centrifugal effect       coriolis effect   \n",
              "2            unbalanced            reactive            exothermic   \n",
              "3            beta decay         gamma decay           alpha decay   \n",
              "4      greenhouse gases     carbon and smog         smoke and ash   \n",
              "...                 ...                 ...                   ...   \n",
              "11674           protons            proteins              peptides   \n",
              "11675       temperature          volatility         rate of decay   \n",
              "11676           bisomes             monomes                biomes   \n",
              "11677       light speed           ion speed            supersonic   \n",
              "11678              cell              marrow                 organ   \n",
              "\n",
              "                                                 support  \n",
              "0      Mesophiles grow best in moderate temperature, ...  \n",
              "1      Without Coriolis Effect the global winds would...  \n",
              "2      Summary Changes of state are examples of phase...  \n",
              "3      All radioactive decay is dangerous to living t...  \n",
              "4      Example 3.5 Calculating Projectile Motion: Hot...  \n",
              "...                                                  ...  \n",
              "11674  Protein A large part of protein digestion take...  \n",
              "11675  The rate of decay of a radioactive substance i...  \n",
              "11676  Terrestrial ecosystems, also known for their d...  \n",
              "11677  The modern day formulation of gun powder is ca...  \n",
              "11678  An organ is a structure composed of two or mor...  \n",
              "\n",
              "[11679 rows x 6 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(r\"C:\\Users\\Arun\\Downloads\\train.csv\\train.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3fb3f8",
      "metadata": {
        "id": "cf3fb3f8"
      },
      "outputs": [],
      "source": [
        "df.fillna(\"<pad>\",inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d21e90c6",
      "metadata": {
        "id": "d21e90c6"
      },
      "outputs": [],
      "source": [
        "x=df[\"question\"].to_list()\n",
        "y=df[\"support\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016cc529",
      "metadata": {
        "id": "016cc529"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "def tokenize(text):\n",
        "    tokens=[word_tokenize(row) for row in text]\n",
        "    return tokens\n",
        "x_tokens=tokenize(x)\n",
        "y_tokens=tokenize(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81948f16",
      "metadata": {
        "id": "81948f16"
      },
      "outputs": [],
      "source": [
        "def sequence(tokens):\n",
        "    seq=[]\n",
        "    for row in tokens:\n",
        "        for word in row:\n",
        "            seq.append(word)\n",
        "    return seq\n",
        "x_seq=sequence(x_tokens)\n",
        "y_seq=sequence(y_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28307928",
      "metadata": {
        "id": "28307928"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "def dict_creater(tokens):\n",
        "    word_count=Counter(tokens)\n",
        "    new_list={\"<pad>\":0,\"<unk>\":1}\n",
        "    for key in word_count:\n",
        "        if key not in new_list:\n",
        "            new_list[key]=len(new_list)\n",
        "    return new_list\n",
        "x_dict=dict_creater(x_seq)\n",
        "y_dict=dict_creater(y_seq)\n",
        "y_vocab_size=len(y_dict)\n",
        "x_vocab_size=len(x_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0196df9",
      "metadata": {
        "id": "a0196df9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "max_len = 20\n",
        "\n",
        "def data_creator(tokens, dicti, max_len):\n",
        "    new_list = []\n",
        "    for row in tokens:\n",
        "        data = [dicti.get(word, dicti[\"<unk>\"]) for word in row]\n",
        "        if len(data) <= max_len:\n",
        "            data = data + [dicti[\"<pad>\"]] * (max_len - len(data))\n",
        "        else:\n",
        "            data = data[:max_len]\n",
        "        new_list.append(data)\n",
        "    return new_list\n",
        "\n",
        "x_data = data_creator(x_tokens, x_dict, max_len)\n",
        "y_data = data_creator(y_tokens, y_dict, max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97fd8c8",
      "metadata": {
        "id": "a97fd8c8"
      },
      "outputs": [],
      "source": [
        "y_data=torch.tensor(y_data,dtype=torch.long)\n",
        "x_data=torch.tensor(x_data,dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3f2a17",
      "metadata": {
        "id": "ae3f2a17"
      },
      "outputs": [],
      "source": [
        "import  torch.nn as nn\n",
        "import math\n",
        "class positional_encooding(nn.Module):\n",
        "\n",
        "    def __init__(self,max_len,d_model):\n",
        "        super().__init__()\n",
        "\n",
        "        pe=torch.zeros(max_len,d_model)\n",
        "        pos=torch.arange(0,max_len).unsqueeze(1)\n",
        "        div_term=torch.exp(torch.arange(0,d_model,2)*(-math.log(10000.0)/d_model))\n",
        "        pe[:,0::2]=torch.sin(pos*div_term)\n",
        "        pe[:,1::2]=torch.cos(pos*div_term)\n",
        "        pe=pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\",pe)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x+self.pe[:,:x.size(1)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4261f0c",
      "metadata": {
        "id": "c4261f0c"
      },
      "outputs": [],
      "source": [
        "class attention(nn.Module):\n",
        "    def __init__(self,d_model,num_heads):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(d_model,d_model)\n",
        "        self.k_linear = nn.Linear(d_model,d_model)\n",
        "        self.v_linear = nn.Linear(d_model,d_model)\n",
        "        self.out = nn.Linear(d_model,d_model)\n",
        "\n",
        "    def forward(self,q,k,v,mask=None):\n",
        "        print(q.shape[0])\n",
        "        batch_size=q.shape[0]\n",
        "\n",
        "        q = self.q_linear(q).view(batch_size,-1,self.num_heads,self.d_k).transpose(1,2)\n",
        "        k = self.q_linear(k).view(batch_size,-1,self.num_heads,self.d_k).transpose(1,2)\n",
        "        v = self.q_linear(v).view(batch_size,-1,self.num_heads,self.d_k).transpose(1,2)\n",
        "\n",
        "        scores = torch.matmul(q,k.transpose(-2,-1)/math.sqrt(self.d_k))\n",
        "\n",
        "        if mask is not None:\n",
        "            scores=torch.masked_fill(mask==0,float(\"inf\"))\n",
        "\n",
        "        attn=torch.softmax(scores,dim=-1)\n",
        "        output=torch.matmul(attn,v)\n",
        "        output=output.transpose(1,2).contiguous().view(batch_size,-1,self.num_heads*self.d_k)\n",
        "\n",
        "        return self.out(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba71185",
      "metadata": {
        "id": "aba71185"
      },
      "outputs": [],
      "source": [
        "class feedforward(nn.Module):\n",
        "    def __init__(self,d_model,d_ff,drop):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(d_model,d_ff),nn.ReLU(),nn.Dropout(drop),nn.Linear(d_ff,d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        return self.features(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a752b0",
      "metadata": {
        "id": "27a752b0"
      },
      "outputs": [],
      "source": [
        "class trasnformerencoder(nn.Module):\n",
        "    def __init__(self,d_model,num_heads,d_ff,drop=0.2):\n",
        "        super().__init__()\n",
        "        self.attn=attention(d_model,num_heads)\n",
        "        self.ff=feedforward(d_model,d_ff,drop)\n",
        "        self.norm1=nn.LayerNorm(d_model)\n",
        "        self.norm2=nn.LayerNorm(d_model)\n",
        "        self.dropout=nn.Dropout(drop)\n",
        "\n",
        "    def forward(self,x,mask=None):\n",
        "        x2=self.norm1(x+self.dropout(self.attn(x,x,x,mask)))\n",
        "        x3=self.ff(x2)\n",
        "        x=self.norm2(x2+self.dropout(self.attn(x3,x3,x3,mask)))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd553986",
      "metadata": {
        "id": "bd553986"
      },
      "outputs": [],
      "source": [
        "class transformer_decoder(nn.Module):\n",
        "    def __init__(self,d_model,num_heads,d_ff,drop=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn=attention(d_model,num_heads)\n",
        "        self.cross_attnn=attention(d_model,num_heads)\n",
        "        self.ff=feedforward(d_model,d_ff,drop)\n",
        "        self.norm1=nn.LayerNorm(d_model)\n",
        "        self.norm2=nn.LayerNorm(d_model)\n",
        "        self.norm3=nn.LayerNorm(d_model)\n",
        "        self.dropout=nn.Dropout(drop)\n",
        "\n",
        "    def forward(self,src,tgt,x,src_mask=None,mask=None):\n",
        "\n",
        "        self_attn=self.attn(x,x,x,mask)\n",
        "        norm_attn=self.norm1(x+self.dropout(self_attn))\n",
        "        cross_attn=self.cross_attnn(norm_attn,src,tgt,src_mask)\n",
        "        cross_norm=self.norm2(x+self.dropout(cross_attn))\n",
        "        ff=self.ff(cross_norm)\n",
        "        ff_norm=self.norm3(x+self.dropout(ff))\n",
        "\n",
        "        return ff_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e64475c",
      "metadata": {
        "id": "0e64475c",
        "outputId": "4fa252f9-f7cb-4c26-be62-bc8ecbd07e07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11679"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae35bde",
      "metadata": {
        "id": "9ae35bde"
      },
      "outputs": [],
      "source": [
        "class transformer(nn.Module):\n",
        "    def __init__(self,d_model,xvocab_size=10,yvocab_size=10,max_len=10,num_heads=10,d_ff=1024,drop=0.2,num_layers=6,num_classes=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.src_embedding=nn.Embedding(xvocab_size,d_model)\n",
        "        self.tgt_embedding=nn.Embedding(yvocab_size,d_model)\n",
        "\n",
        "        self.pe=positional_encooding(max_len,d_model)\n",
        "\n",
        "        encoder=trasnformerencoder(d_model,num_heads,d_ff,drop)\n",
        "        decoder=transformer_decoder(d_model,num_heads,d_ff,drop)\n",
        "\n",
        "        self.decoder_layers=nn.ModuleList([decoder for _ in range(num_layers)])\n",
        "        self.encoder_layers=nn.ModuleList([encoder for _ in range(num_layers)])\n",
        "        self.fc_out=nn.Linear(d_model,num_classes)\n",
        "\n",
        "    def forward(self,src,tgt,src_mask=None,tgt_mask=None):\n",
        "\n",
        "        x=self.pe(self.src_embedding(src))\n",
        "        y=self.pe(self.tgt_embedding(tgt))\n",
        "\n",
        "        for layers in self.encoder_layers:\n",
        "            x=layers(x,src_mask)\n",
        "\n",
        "        for layers in self.decoder_layers:\n",
        "            y=layers(y,x,src_mask,tgt_mask)\n",
        "\n",
        "        return self.fc_out(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "426fcafc",
      "metadata": {
        "id": "426fcafc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset=TensorDataset(x_data,y_data)\n",
        "train_data,val_data=train_test_split(dataset,test_size=0.3,random_state=42)\n",
        "train_data_loader=DataLoader(train_data,batch_size=256)\n",
        "val_data_loader=DataLoader(val_data,batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea547b1c",
      "metadata": {
        "id": "ea547b1c"
      },
      "outputs": [],
      "source": [
        "device=(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=transformer(xvocab_size=x_vocab_size,yvocab_size=y_vocab_size,d_model=512,max_len=200,num_layers=6,num_heads=8,d_ff=2048,num_classes=len(y_dict),drop=0.2).to(device)\n",
        "model_loss=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)\n",
        "scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"min\",factor=0.5,patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296041c8",
      "metadata": {
        "id": "296041c8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class early_stopping(nn.Module):\n",
        "    def __init__(self,min_delta,patience):\n",
        "        super().__init__()\n",
        "        self.min_delta=min_delta\n",
        "        self.partience=patience\n",
        "        self.early_stop=False\n",
        "        self.best_loss=float(\"inf\")\n",
        "        self.counter=0\n",
        "\n",
        "    def __call__(self,val_loss):\n",
        "        if self.min_delta >= val_loss-self.best_loss:\n",
        "            self.counter=0\n",
        "            self.best_loss=val_loss\n",
        "        else:\n",
        "            self.counter+=1\n",
        "            if self.counter>=self.partience:\n",
        "                self.early_stop=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4646665c",
      "metadata": {
        "id": "4646665c"
      },
      "outputs": [],
      "source": [
        "from torch.amp import GradScaler,autocast\n",
        "epochs=50\n",
        "stopper=early_stopping(1e-4,4)\n",
        "training_loss_store=[]\n",
        "validation_loss_store=[]\n",
        "training_accuracy_store=[]\n",
        "validation_accuracy_store=[]\n",
        "scaler=GradScaler()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running,total,correct=0,0,0\n",
        "    for x,y in train_data_loader:\n",
        "        x,y=x.to(device),y.to(device)\n",
        "\n",
        "        input=y[:,:-1]\n",
        "        target=y[:,1:]\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(\"cuda\"):\n",
        "            output=model(x,input)\n",
        "            output=output.reshape(-1,output.size(-1))\n",
        "            tgt_output=target.reshape(-1)\n",
        "            loss=model_loss(output,tgt_output)\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running+=loss.item()\n",
        "        _,pred=torch.max(output,1)\n",
        "        correct+=(pred==y).sum().item()\n",
        "        total+=y.size(0)\n",
        "\n",
        "\n",
        "    training_loss=running/len(y)\n",
        "    training_acc=correct/total\n",
        "    training_loss_store.append(training_loss)\n",
        "    training_accuracy_store.append(training_acc)\n",
        "\n",
        "    model.eval()\n",
        "    vrunning,vtotal,vcorrect=0,0,0\n",
        "    for vx,vy in val_data_loader:\n",
        "        vx,vy=vx.to(device),vy.to(device)\n",
        "        vinput=vx[:,:-1]\n",
        "        vtarget=vy[:,1:]\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(\"cuda\"):\n",
        "            voutput=model(vx,vtarget)\n",
        "            voutput=voutput.reshape(-1,voutput.size(-1))\n",
        "            vy=vtarget.reshape(-1)\n",
        "            vloss=model_loss(voutput,vy)\n",
        "\n",
        "        vrunning+=vloss.item()\n",
        "        _,vpred=torch.max(voutput,1)\n",
        "        vcorrect+=(vpred==vy).sum().item()\n",
        "        vtotal+=vy.size(0)\n",
        "    val_loss=vrunning/len(vy)\n",
        "    val_acc=vcorrect/vtotal\n",
        "    validation_loss_store.append(val_loss)\n",
        "    validation_accuracy_store.append(val_acc)\n",
        "\n",
        "    print(f\"epoch: {epoch+1} training_loss: {training_loss:.4f} training acc:{training_acc:.2f} validation_loss: {val_loss:.4f} validation_acc: {val_acc:.2f} \")\n",
        "    stopper(val_loss)\n",
        "    if stopper.early_stop:\n",
        "        print(\"early_stopping triggered\")\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}